{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MNIST using Tensorflow. 0.996 \nMi first submission to Kaggle. I achieved a VAL_ACCURACY between 0.9955 and 0.9972 with 30 epochs.  ","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:01:46.853991Z","iopub.execute_input":"2022-08-18T21:01:46.854954Z","iopub.status.idle":"2022-08-18T21:01:53.774014Z","shell.execute_reply.started":"2022-08-18T21:01:46.854832Z","shell.execute_reply":"2022-08-18T21:01:53.772937Z"}}},{"cell_type":"code","source":"import tensorflow as tf\ntf.random.set_seed(42)\nimport numpy as np\n\nfrom tensorflow import keras\nfrom tensorflow.keras.models import load_model\nfrom time import time\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib import rcParams\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-08-22T09:41:49.062989Z","iopub.execute_input":"2022-08-22T09:41:49.063324Z","iopub.status.idle":"2022-08-22T09:41:55.640526Z","shell.execute_reply.started":"2022-08-22T09:41:49.063251Z","shell.execute_reply":"2022-08-22T09:41:55.639571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SUPPORT FUNCTIONS\nFunctions that can be  reused. ","metadata":{}},{"cell_type":"code","source":"#I Use this function to plot the loss and accuracy of the training and validation data \n#of the history received. You can indicate the first epoch to plot. \n#Useful to see the slope of the curve in the last epochs. \n#history--> The history returbed by the fit of the model.\n#firstepoch--> First epoch to show in the plot. \ndef plot_loss_acc(history, firstepoch=0):\n  '''Plots the training and validation loss and accuracy from a history object'''\n  acc = history.history['accuracy']\n  acc = acc[firstepoch:]\n  val_acc = history.history['val_accuracy']\n    \n  val_acc = val_acc[firstepoch:]\n  loss = history.history['loss']\n  loss=loss[firstepoch:]\n  val_loss = history.history['val_loss']\n  val_loss = val_loss[firstepoch:]\n\n  epochs = range(len(acc))\n\n  plt.plot(epochs, acc, 'bo-', label='Training accuracy')\n  plt.plot(epochs, val_acc, 'go-', label='Validation accuracy')\n  plt.title('Training and validation accuracy')\n  plt.legend()\n\n  plt.figure()\n\n  plt.plot(epochs, loss, 'bo-', label='Training Loss')\n  plt.plot(epochs, val_loss, 'go-', label='Validation Loss')\n  plt.title('Training and validation loss')\n  plt.legend()\n\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T09:42:35.762654Z","iopub.execute_input":"2022-08-22T09:42:35.763283Z","iopub.status.idle":"2022-08-22T09:42:35.772090Z","shell.execute_reply.started":"2022-08-22T09:42:35.763244Z","shell.execute_reply":"2022-08-22T09:42:35.770994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Show image. \n#X-->Features. \n#y-->Labels. \n#nrows. \n#ncols. \n#firstimg. \n#numimg-->Number of images to display. \ndef show_img_dataset(X, y=None, nrows = 4, ncols=4, firstimg=100, numimg=4):\n    for i in range(numimg):\n        sp = plt.subplot(nrows, ncols, i + 1)\n\n        sp.axis('Off')\n        plt.imshow(X[firstimg+i], cmap=\"Greys\")\n        if (y is not None): \n            plt.title(y[firstimg+i])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T09:42:41.200105Z","iopub.execute_input":"2022-08-22T09:42:41.200457Z","iopub.status.idle":"2022-08-22T09:42:41.206979Z","shell.execute_reply.started":"2022-08-22T09:42:41.200427Z","shell.execute_reply":"2022-08-22T09:42:41.205889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#return predictions of the model received. \ndef get_predictions(model, X, y):\n    predictions=model.predict(X)  \n    results = pd.DataFrame(data={'Predictions': np.argmax(predictions, axis=1), \n                            'Actuals': np.argmax(y, axis=1)})\n    predictions.shape, y.shape\n    return predictions, results","metadata":{"execution":{"iopub.status.busy":"2022-08-22T09:42:42.284151Z","iopub.execute_input":"2022-08-22T09:42:42.285165Z","iopub.status.idle":"2022-08-22T09:42:42.291379Z","shell.execute_reply.started":"2022-08-22T09:42:42.285115Z","shell.execute_reply":"2022-08-22T09:42:42.289930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"#Read the data from CSV files. \ntrain_df=pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest_df=pd.read_csv('/kaggle/input/digit-recognizer/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-08-22T09:42:44.904243Z","iopub.execute_input":"2022-08-22T09:42:44.905113Z","iopub.status.idle":"2022-08-22T09:42:49.944838Z","shell.execute_reply.started":"2022-08-22T09:42:44.905076Z","shell.execute_reply":"2022-08-22T09:42:49.943665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T09:42:53.735926Z","iopub.execute_input":"2022-08-22T09:42:53.736594Z","iopub.status.idle":"2022-08-22T09:42:53.762622Z","shell.execute_reply.started":"2022-08-22T09:42:53.736556Z","shell.execute_reply":"2022-08-22T09:42:53.761419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Obtain Features and labels. \nX= train_df.drop('label', axis=1)\ny = train_df['label']\n\nX.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-22T09:42:56.157657Z","iopub.execute_input":"2022-08-22T09:42:56.158045Z","iopub.status.idle":"2022-08-22T09:42:56.252396Z","shell.execute_reply.started":"2022-08-22T09:42:56.157991Z","shell.execute_reply":"2022-08-22T09:42:56.251242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.array(X).reshape(X.shape[0], 28, 28)\nX = np.array(X).reshape((-1, 28, 28, 1))\nX_test = np.array(test_df).reshape((-1, 28, 28, 1))\nX.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-22T09:42:56.941340Z","iopub.execute_input":"2022-08-22T09:42:56.941664Z","iopub.status.idle":"2022-08-22T09:42:57.206088Z","shell.execute_reply.started":"2022-08-22T09:42:56.941636Z","shell.execute_reply":"2022-08-22T09:42:57.204978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_img_dataset(X, y = y, firstimg=780, nrows = 2, ncols=4, numimg=8)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T09:42:57.821112Z","iopub.execute_input":"2022-08-22T09:42:57.822199Z","iopub.status.idle":"2022-08-22T09:42:58.151065Z","shell.execute_reply.started":"2022-08-22T09:42:57.822151Z","shell.execute_reply":"2022-08-22T09:42:58.149950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_img_dataset(X_test, firstimg=780, nrows = 2, ncols=4, numimg=8)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T09:42:58.844410Z","iopub.execute_input":"2022-08-22T09:42:58.845434Z","iopub.status.idle":"2022-08-22T09:42:59.148864Z","shell.execute_reply.started":"2022-08-22T09:42:58.845389Z","shell.execute_reply":"2022-08-22T09:42:59.147951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Normalization and One Hot Encoding. \nX = X/255\nX_test = X_test/255\n\ny = train_df['label']\ny = tf.keras.utils.to_categorical(y, num_classes = 10)\nX.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-22T09:42:59.463881Z","iopub.execute_input":"2022-08-22T09:42:59.464510Z","iopub.status.idle":"2022-08-22T09:42:59.642615Z","shell.execute_reply.started":"2022-08-22T09:42:59.464474Z","shell.execute_reply":"2022-08-22T09:42:59.641686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#obtainig from X and y training and validating data. \nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.05, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T09:43:01.118246Z","iopub.execute_input":"2022-08-22T09:43:01.118878Z","iopub.status.idle":"2022-08-22T09:43:01.490881Z","shell.execute_reply.started":"2022-08-22T09:43:01.118840Z","shell.execute_reply":"2022-08-22T09:43:01.489867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#just to cleant a little bit the memory, but it's no t necessary. \ndel X, y, train_df, test_df","metadata":{"execution":{"iopub.status.busy":"2022-08-22T09:43:03.200689Z","iopub.execute_input":"2022-08-22T09:43:03.201296Z","iopub.status.idle":"2022-08-22T09:43:03.207299Z","shell.execute_reply.started":"2022-08-22T09:43:03.201249Z","shell.execute_reply":"2022-08-22T09:43:03.206122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_val.shape, y_train.shape, y_val.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-22T09:43:06.498678Z","iopub.execute_input":"2022-08-22T09:43:06.499376Z","iopub.status.idle":"2022-08-22T09:43:06.506019Z","shell.execute_reply.started":"2022-08-22T09:43:06.499335Z","shell.execute_reply":"2022-08-22T09:43:06.505065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation\nJust a little bit of DataAugmentation. \n\nVertical or horizontal flips are contraproducent, but\na bit of shift and zoom helps with the final accuracy. ","metadata":{}},{"cell_type":"code","source":"#Just a little bit of DataAugmentation. \n#Vertical or horizontal flips are contraproducent, but\n#a bit of shioft helps\nfrom keras.preprocessing.image import ImageDataGenerator\n\nx_trainr = X_train.reshape(-1, 28, 28, 1)\nx_valr = X_val.reshape(-1, 28, 28, 1)\n\ndatagen = ImageDataGenerator(\n        rotation_range=5, \n        zoom_range = 0.1, \n        width_shift_range=0.05, \n        height_shift_range=0.05,    \n)  \n\nX_mean = X_train.mean(axis=0)\ndatagen.fit(X_train - X_mean)\ntrain_gen = datagen.flow(x_trainr, y_train, batch_size=100)\nval_gen = datagen.flow(x_valr, y_val, batch_size=100)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T09:57:56.651149Z","iopub.execute_input":"2022-08-22T09:57:56.651508Z","iopub.status.idle":"2022-08-22T09:57:56.904920Z","shell.execute_reply.started":"2022-08-22T09:57:56.651475Z","shell.execute_reply":"2022-08-22T09:57:56.903948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The Model\nI used two callbacks. \n\n**ModelCheckPoint**: to save the best model and load it after the fit. Rareley the result of the last epoch is the best. In the param **monitor** you can iondicate wich value you want to watch, the default is loss, but I prefer to improve the val_accuracy. Not sure if we can get a better score in the test dataset if we get the model with the best loss value instead of the one with the best accuracy. \n\n**ReduceLROnPlateau**: It reduces the **learning_rate** after the **epochs** indicated when there are no improvement in the **monitor** variable indicated. We are going to train just for 30 epochs and I indicated a really short patiente of 3 **epochs**. \n\nMaybe it's important to mention that I replaced the Dropout layer for a SpatialDropout one. Is similar, but it affects to an entirely channel. \n\n**Dropout** \n[[1, 1, 1, 1]\n[1, 1, 1, 1]\n[1, 1, 1, 1]]\n\nTransforms to: \n\n[[0, 1, 1, 1]\n[1, 1, 0, 1]\n[1, 0, 1, 1]]\n\n\n**Spatial Dropout **\n\n[[1, 1, 1, 1]\n[1, 1, 1, 1]\n[1, 1, 1, 1]]\n\nTransforms to: \n\n[[1, 1, 0, 1]\n[1, 1, 0, 1]\n[1, 1, 0, 1]]\n","metadata":{}},{"cell_type":"code","source":"def scheduler(epoch, lr):\n    if epoch < 20:\n        return lr\n    else:\n        return lr * tf.math.exp(-0.1)  \n\nreduce_last_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T09:43:15.647175Z","iopub.execute_input":"2022-08-22T09:43:15.647521Z","iopub.status.idle":"2022-08-22T09:43:15.652669Z","shell.execute_reply.started":"2022-08-22T09:43:15.647490Z","shell.execute_reply":"2022-08-22T09:43:15.651524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.backend.clear_session()\n\ncpDA4 = tf.keras.callbacks.ModelCheckpoint('modelDA4.h5', \n                                           mode='max', monitor='val_accuracy', \n                                           verbose=1, \n                                           save_best_only=True)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1,\n                              patience=3, verbose=1, mode='auto')\n\nreduce_last_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\nmodelDA4 = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(32, (5,5), strides=2, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.SpatialDropout2D(0.2),\n\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64, (5,5), strides=2, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.2),\n\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.4),  \n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')])\nmodelDA4.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-22T10:04:14.949146Z","iopub.execute_input":"2022-08-22T10:04:14.949717Z","iopub.status.idle":"2022-08-22T10:04:15.111941Z","shell.execute_reply.started":"2022-08-22T10:04:14.949681Z","shell.execute_reply":"2022-08-22T10:04:15.110926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelDA4.compile(optimizer='adam', \n                  loss='categorical_crossentropy', \n                  metrics=['accuracy']) \n\n\nhistoryDA4 = modelDA4.fit(train_gen, \n                        steps_per_epoch=len(train_gen),\n                        validation_data=val_gen,\n                        validation_steps=len(val_gen), \n                        epochs=30, \n                        verbose=1, \n                        callbacks=[cpDA4, reduce_lr]\n                        )","metadata":{"execution":{"iopub.status.busy":"2022-08-22T10:04:18.158395Z","iopub.execute_input":"2022-08-22T10:04:18.158751Z","iopub.status.idle":"2022-08-22T10:10:06.298525Z","shell.execute_reply.started":"2022-08-22T10:04:18.158721Z","shell.execute_reply":"2022-08-22T10:10:06.297490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_acc(historyDA4, 5)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T10:10:16.750275Z","iopub.execute_input":"2022-08-22T10:10:16.750628Z","iopub.status.idle":"2022-08-22T10:10:17.140521Z","shell.execute_reply.started":"2022-08-22T10:10:16.750598Z","shell.execute_reply":"2022-08-22T10:10:17.139624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction, results = get_predictions(modelDA4, X_val, y_val)\nresults","metadata":{"execution":{"iopub.status.busy":"2022-08-22T10:10:55.391783Z","iopub.execute_input":"2022-08-22T10:10:55.392698Z","iopub.status.idle":"2022-08-22T10:10:55.902989Z","shell.execute_reply.started":"2022-08-22T10:10:55.392659Z","shell.execute_reply":"2022-08-22T10:10:55.901915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_loss, validation_accuracy = modelDA4.evaluate(X_val, y_val)\nmodelDA4_loaded = load_model('modelDA4.h5')\nvalidation_loss_loaded, validation_accuracy_loaded = modelDA4_loaded.evaluate(X_val, y_val)\nprint('Validation loss: ', validation_loss)\nprint('Validation accuracy: ', validation_accuracy)\n\nprint('Validation loss loaded: ', validation_loss_loaded)\nprint('Validation accuracy loaded: ', validation_accuracy_loaded)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T10:10:58.328888Z","iopub.execute_input":"2022-08-22T10:10:58.329573Z","iopub.status.idle":"2022-08-22T10:10:59.594763Z","shell.execute_reply.started":"2022-08-22T10:10:58.329535Z","shell.execute_reply":"2022-08-22T10:10:59.593820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ny_pred=modelDA4_loaded.predict(X_test)\nresults = np.argmax(y_pred, axis=1)\nresults.shape, results","metadata":{"execution":{"iopub.status.busy":"2022-08-22T10:10:59.597680Z","iopub.execute_input":"2022-08-22T10:10:59.597981Z","iopub.status.idle":"2022-08-22T10:11:02.520990Z","shell.execute_reply.started":"2022-08-22T10:10:59.597953Z","shell.execute_reply":"2022-08-22T10:11:02.519921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_id = pd.Series(range(1,28001),name='ImageId')\ny_preds = pd.Series(results,name = 'Label')\npred = pd.concat([image_id,y_preds],axis=1)\npred.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T10:11:02.522994Z","iopub.execute_input":"2022-08-22T10:11:02.523382Z","iopub.status.idle":"2022-08-22T10:11:02.558259Z","shell.execute_reply.started":"2022-08-22T10:11:02.523346Z","shell.execute_reply":"2022-08-22T10:11:02.557383Z"},"trusted":true},"execution_count":null,"outputs":[]}]}