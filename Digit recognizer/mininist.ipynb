{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MNIST using Tensorflow. 0.996 \nMi first submission to Kaggle. I achieved a VAL_ACCURACY between 0.9955 and 0.9972 with 30 epochs.  ","metadata":{"execution":{"iopub.status.busy":"2022-08-18T21:01:46.853991Z","iopub.execute_input":"2022-08-18T21:01:46.854954Z","iopub.status.idle":"2022-08-18T21:01:53.774014Z","shell.execute_reply.started":"2022-08-18T21:01:46.854832Z","shell.execute_reply":"2022-08-18T21:01:53.772937Z"}}},{"cell_type":"code","source":"import tensorflow as tf\ntf.random.set_seed(42)\nimport numpy as np\n\nfrom tensorflow import keras\nfrom tensorflow.keras.models import load_model\nfrom time import time\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib import rcParams\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:22:44.484527Z","iopub.execute_input":"2022-08-18T22:22:44.484910Z","iopub.status.idle":"2022-08-18T22:22:45.279424Z","shell.execute_reply.started":"2022-08-18T22:22:44.484879Z","shell.execute_reply":"2022-08-18T22:22:45.278470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SUPPORT FUNCTIONS\nFunctions that can be  reused. ","metadata":{}},{"cell_type":"code","source":"#I Use this function to plot the loss and accuracy of the training and validation data \n#of the history received. You can indicate the first epoch to plot. \n#Useful to see the slope of the curve in the last epochs. \n#history--> The history returbed by the fit of the model.\n#firstepoch--> First epoch to show in the plot. \ndef plot_loss_acc(history, firstepoch=0):\n  '''Plots the training and validation loss and accuracy from a history object'''\n  acc = history.history['accuracy']\n  acc = acc[firstepoch:]\n  val_acc = history.history['val_accuracy']\n  val_acc = val_acc[firstepoch:]\n  loss = history.history['loss']\n  loss=loss[firstepoch:]\n  val_loss = history.history['val_loss']\n  val_loss = val_loss[firstepoch:]\n\n  epochs = range(len(acc))\n\n  plt.plot(epochs, acc, 'bo-', label='Training accuracy')\n  plt.plot(epochs, val_acc, 'go-', label='Validation accuracy')\n  plt.title('Training and validation accuracy')\n  plt.legend()\n\n  plt.figure()\n\n  plt.plot(epochs, loss, 'bo-', label='Training Loss')\n  plt.plot(epochs, val_loss, 'go-', label='Validation Loss')\n  plt.title('Training and validation loss')\n  plt.legend()\n\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:22:54.544103Z","iopub.execute_input":"2022-08-18T22:22:54.544493Z","iopub.status.idle":"2022-08-18T22:22:54.552790Z","shell.execute_reply.started":"2022-08-18T22:22:54.544459Z","shell.execute_reply":"2022-08-18T22:22:54.551755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Show image. \n#X-->Features. \n#y-->Labels. \n#nrows. \n#ncols. \n#firstimg. \n#numimg-->Number of images to display. \ndef show_img_dataset(X, y=None, nrows = 4, ncols=4, firstimg=100, numimg=4):\n    for i in range(numimg):\n        sp = plt.subplot(nrows, ncols, i + 1)\n\n        sp.axis('Off')\n        plt.imshow(X[firstimg+i], cmap=\"Greys\")\n        if (y is not None): \n            plt.title(y[firstimg+i])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:20:09.024047Z","iopub.execute_input":"2022-08-18T22:20:09.024315Z","iopub.status.idle":"2022-08-18T22:20:09.032426Z","shell.execute_reply.started":"2022-08-18T22:20:09.024289Z","shell.execute_reply":"2022-08-18T22:20:09.031434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#return predictions of the model received. \ndef get_predictions(model, X, y):\n    predictions=model.predict(X)  \n    results = pd.DataFrame(data={'Predictions': np.argmax(predictions, axis=1), \n                            'Actuals': np.argmax(y, axis=1)})\n    predictions.shape, y.shape\n    return predictions, results","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:20:09.034970Z","iopub.execute_input":"2022-08-18T22:20:09.035712Z","iopub.status.idle":"2022-08-18T22:20:09.041859Z","shell.execute_reply.started":"2022-08-18T22:20:09.035677Z","shell.execute_reply":"2022-08-18T22:20:09.040876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"#Read the data from CSV files. \ntrain_df=pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest_df=pd.read_csv('/kaggle/input/digit-recognizer/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:23:01.134433Z","iopub.execute_input":"2022-08-18T22:23:01.135136Z","iopub.status.idle":"2022-08-18T22:23:05.836664Z","shell.execute_reply.started":"2022-08-18T22:23:01.135101Z","shell.execute_reply":"2022-08-18T22:23:05.835633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:23:08.315309Z","iopub.execute_input":"2022-08-18T22:23:08.316006Z","iopub.status.idle":"2022-08-18T22:23:08.342341Z","shell.execute_reply.started":"2022-08-18T22:23:08.315969Z","shell.execute_reply":"2022-08-18T22:23:08.341427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Obtain Features and labels. \nX= train_df.drop('label', axis=1)\ny = train_df['label']\n\nX.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:23:09.606751Z","iopub.execute_input":"2022-08-18T22:23:09.607115Z","iopub.status.idle":"2022-08-18T22:23:09.698730Z","shell.execute_reply.started":"2022-08-18T22:23:09.607085Z","shell.execute_reply":"2022-08-18T22:23:09.697690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.array(X).reshape(X.shape[0], 28, 28)\nX = np.array(X).reshape((-1, 28, 28, 1))\nX_test = np.array(test_df).reshape((-1, 28, 28, 1))\nX.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:23:11.408758Z","iopub.execute_input":"2022-08-18T22:23:11.409906Z","iopub.status.idle":"2022-08-18T22:23:11.675658Z","shell.execute_reply.started":"2022-08-18T22:23:11.409854Z","shell.execute_reply":"2022-08-18T22:23:11.674713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_img_dataset(X, y = y, firstimg=780, nrows = 2, ncols=4, numimg=8)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:23:11.868664Z","iopub.execute_input":"2022-08-18T22:23:11.869562Z","iopub.status.idle":"2022-08-18T22:23:12.211324Z","shell.execute_reply.started":"2022-08-18T22:23:11.869513Z","shell.execute_reply":"2022-08-18T22:23:12.210363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_img_dataset(X_test, firstimg=780, nrows = 2, ncols=4, numimg=8)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:23:13.512143Z","iopub.execute_input":"2022-08-18T22:23:13.513236Z","iopub.status.idle":"2022-08-18T22:23:13.810331Z","shell.execute_reply.started":"2022-08-18T22:23:13.513190Z","shell.execute_reply":"2022-08-18T22:23:13.809380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Normalization and One Hot Encoding. \nX = X/255\nX_test = X_test/255\n\ny = train_df['label']\ny = tf.keras.utils.to_categorical(y, num_classes = 10)\nX.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:23:15.664730Z","iopub.execute_input":"2022-08-18T22:23:15.665335Z","iopub.status.idle":"2022-08-18T22:23:15.841515Z","shell.execute_reply.started":"2022-08-18T22:23:15.665297Z","shell.execute_reply":"2022-08-18T22:23:15.840319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#obtainig from X and y training and validating data. \nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:23:17.388001Z","iopub.execute_input":"2022-08-18T22:23:17.388989Z","iopub.status.idle":"2022-08-18T22:23:17.768398Z","shell.execute_reply.started":"2022-08-18T22:23:17.388939Z","shell.execute_reply":"2022-08-18T22:23:17.767445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#just to cleant a little bit the memory, but it's no t necessary. \ndel X, y, train_df, test_df","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:23:18.705691Z","iopub.execute_input":"2022-08-18T22:23:18.706052Z","iopub.status.idle":"2022-08-18T22:23:18.712377Z","shell.execute_reply.started":"2022-08-18T22:23:18.706022Z","shell.execute_reply":"2022-08-18T22:23:18.711253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_val.shape, y_train.shape, y_val.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:23:20.392711Z","iopub.execute_input":"2022-08-18T22:23:20.393715Z","iopub.status.idle":"2022-08-18T22:23:20.401523Z","shell.execute_reply.started":"2022-08-18T22:23:20.393664Z","shell.execute_reply":"2022-08-18T22:23:20.400448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation\nJust a little bit of DataAugmentation. \n\nVertical or horizontal flips are contraproducent, but\na bit of shift and zoom helps with the final accuracy. ","metadata":{}},{"cell_type":"code","source":"#Just a little bit of DataAugmentation. \n#Vertical or horizontal flips are contraproducent, but\n#a bit of shioft helps\nfrom keras.preprocessing.image import ImageDataGenerator\n\nx_trainr = X_train.reshape(-1, 28, 28, 1)\nx_valr = X_val.reshape(-1, 28, 28, 1)\n\ndatagen = ImageDataGenerator(\n        rotation_range=5, \n        zoom_range = 0.1, \n        width_shift_range=0.05, \n        height_shift_range=0.05,    \n)  \n\nX_mean = X_train.mean(axis=0)\ndatagen.fit(X_train - X_mean)\ntrain_gen = datagen.flow(x_trainr, y_train, batch_size=128)\ntest_gen = datagen.flow(x_valr, y_val, batch_size=128)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:23:24.085928Z","iopub.execute_input":"2022-08-18T22:23:24.086462Z","iopub.status.idle":"2022-08-18T22:23:24.354057Z","shell.execute_reply.started":"2022-08-18T22:23:24.086396Z","shell.execute_reply":"2022-08-18T22:23:24.352963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The Model\nI used two callbacks. \n\n**ModelCheckPoint**: to save the best model and load it after the fit. Rareley the result of the last epoch is the best. In the param **monitor** you can iondicate wich value you want to watch, the default is loss, but I prefer to improve the val_accuracy. Not sure if we can get a better score in the test dataset if we get the model with the best loss value instead of the one with the best accuracy. \n\n**ReduceLROnPlateau**: It reduces the **learning_rate** after the **epochs** indicated when there are no improvement in the **monitor** variable indicated. We are going to train just for 30 epochs and I indicated a really short patiente of 3 **epochs**. \n\nMaybe it's important to mention that I replaced the Dropout layer for a SpatialDropout one. Is similar, but it affects to an entirely channel. \n\n**Dropout** \n[[1, 1, 1, 1]\n[1, 1, 1, 1]\n[1, 1, 1, 1]]\n\nTransforms to: \n\n[[0, 1, 1, 1]\n[1, 1, 0, 1]\n[1, 0, 1, 1]]\n\n\n**Spatial Dropout **\n\n[[1, 1, 1, 1]\n[1, 1, 1, 1]\n[1, 1, 1, 1]]\n\nTransforms to: \n\n[[1, 1, 0, 1]\n[1, 1, 0, 1]\n[1, 1, 0, 1]]\n","metadata":{}},{"cell_type":"code","source":"keras.backend.clear_session()\n\ncpDA4 = tf.keras.callbacks.ModelCheckpoint('modelDA4.h5', \n                                           mode='max', monitor='val_accuracy', \n                                           verbose=1, \n                                           save_best_only=True)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1,\n                              patience=3, min_lr=0.0001, verbose=1, mode='auto')\nmodelDA4 = tf.keras.models.Sequential([\n                                    tf.keras.layers.Conv2D(64, (5,5), activation='relu', input_shape=(28, 28, 1)),\n                                    tf.keras.layers.BatchNormalization(),   \n                                    tf.keras.layers.Conv2D(64, (5,5), activation='relu'),\n                                    tf.keras.layers.MaxPooling2D(2, 2),\n                                    tf.keras.layers.SpatialDropout2D(0.4),\n                                    \n\n                                    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n                                    tf.keras.layers.BatchNormalization(), \n                                    tf.keras.layers.Conv2D(128, (3,3), activation='relu'), \n                                    tf.keras.layers.MaxPooling2D(2, 2),\n                                    tf.keras.layers.SpatialDropout2D(0.4),\n\n                                    tf.keras.layers.Flatten(), \n                                    tf.keras.layers.Dense(128, activation='relu'),\n                                    tf.keras.layers.Dense(10, activation='softmax')])\nmodelDA4.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:24:45.041121Z","iopub.execute_input":"2022-08-18T22:24:45.041608Z","iopub.status.idle":"2022-08-18T22:24:47.995694Z","shell.execute_reply.started":"2022-08-18T22:24:45.041567Z","shell.execute_reply":"2022-08-18T22:24:47.994713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelDA4.compile(optimizer='adam', \n                  loss='categorical_crossentropy', \n                  metrics=['accuracy']) \n\n\nhistoryDA4 = modelDA4.fit(train_gen, \n                        validation_data=(X_val, y_val), \n                        epochs=30, \n                        steps_per_epoch=len(train_gen), \n                        verbose=1, \n                        callbacks=[cpDA4, reduce_lr]\n                        )","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:24:59.673889Z","iopub.execute_input":"2022-08-18T22:24:59.674669Z","iopub.status.idle":"2022-08-18T22:29:38.635253Z","shell.execute_reply.started":"2022-08-18T22:24:59.674625Z","shell.execute_reply":"2022-08-18T22:29:38.634115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_acc(historyDA4, 5)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:29:47.974779Z","iopub.execute_input":"2022-08-18T22:29:47.975138Z","iopub.status.idle":"2022-08-18T22:29:48.366835Z","shell.execute_reply.started":"2022-08-18T22:29:47.975106Z","shell.execute_reply":"2022-08-18T22:29:48.365846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction, results = get_predictions(modelDA4, X_val, y_val)\nresults","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:29:57.718743Z","iopub.execute_input":"2022-08-18T22:29:57.719228Z","iopub.status.idle":"2022-08-18T22:29:58.522444Z","shell.execute_reply.started":"2022-08-18T22:29:57.719193Z","shell.execute_reply":"2022-08-18T22:29:58.521362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_loss, validation_accuracy = modelDA4.evaluate(X_val, y_val)\nmodelDA4_loaded = load_model('modelDA4.h5')\nvalidation_loss_loaded, validation_accuracy_loaded = modelDA4_loaded.evaluate(X_val, y_val)\nprint('Validation loss: ', validation_loss)\nprint('Validation accuracy: ', validation_accuracy)\n\nprint('Validation loss loaded: ', validation_loss_loaded)\nprint('Validation accuracy loaded: ', validation_accuracy_loaded)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:30:03.275515Z","iopub.execute_input":"2022-08-18T22:30:03.275882Z","iopub.status.idle":"2022-08-18T22:30:05.391554Z","shell.execute_reply.started":"2022-08-18T22:30:03.275849Z","shell.execute_reply":"2022-08-18T22:30:05.390461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ny_pred=modelDA4_loaded.predict(X_test)\nresults = np.argmax(y_pred, axis=1)\nresults.shape, results","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:38:25.715033Z","iopub.execute_input":"2022-08-18T22:38:25.715704Z","iopub.status.idle":"2022-08-18T22:38:27.248264Z","shell.execute_reply.started":"2022-08-18T22:38:25.715668Z","shell.execute_reply":"2022-08-18T22:38:27.247329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_id = pd.Series(range(1,28001),name='ImageId')\ny_preds = pd.Series(results,name = 'Label')\npred = pd.concat([image_id,y_preds],axis=1)\npred.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-18T22:41:05.752470Z","iopub.execute_input":"2022-08-18T22:41:05.753062Z","iopub.status.idle":"2022-08-18T22:41:05.786711Z","shell.execute_reply.started":"2022-08-18T22:41:05.753028Z","shell.execute_reply":"2022-08-18T22:41:05.785801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}